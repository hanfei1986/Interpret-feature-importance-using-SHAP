# Interpret-feature-importance-using-SHAP
SHAP is a fancy tool for interpreting feature importance in machine learning tasks. This Jupyter notebook gives a demonstration.

![image](https://github.com/hanfei1986/Interpret-feature-importance-using-SHAP/assets/59255164/47483be5-6b3e-4082-8ee2-61b7fc3a21c5)

