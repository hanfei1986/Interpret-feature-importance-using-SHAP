# Interpret-feature-importance-using-SHAP
SHAP is a fancy tool for interpreting feature importance in machine learning tasks. This Jupyter notebook gives a demonstration.

![image](https://github.com/hanfei1986/Interpret-feature-importance-using-SHAP/assets/59255164/cc9b90cf-d9a0-407e-a88f-bf9f0db47cf1)


